{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import ConvexHull\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import copy\n",
    "import jax.numpy as jnp\n",
    "import jax.nn as nn\n",
    "import numpy as np\n",
    "from jax import random, grad, jit, vmap\n",
    "from functools import partial\n",
    "key = random.PRNGKey(0)\n",
    "#import jax.example_libraries.optimizers as optimizers\n",
    "#from NODE_ICNN_CANN_MF_fns import *\n",
    "import pickle\n",
    "from jax.config import config\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from jax.experimental import optimizers\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = '/scratch/brown/jbarsima/RVE/RVE_adip_size/tess_files/RVE_2.tess'\n",
    "data = []\n",
    "with open(file, 'r') as f:\n",
    "    for line in f:\n",
    "        line_data = line.strip().split()\n",
    "        # append the data from this line to the list\n",
    "        data.append(line_data)\n",
    "\n",
    "## VERTEX DATA\n",
    "# loop through each element of the 'data' list\n",
    "for i in range(len(data)):\n",
    "    # check if the current element matches the search value\n",
    "    if data[i] == ['**vertex']:\n",
    "        #print(f\"Found '**vertex' at index {i}.\")\n",
    "        vertex_in = i #Index for vertex\n",
    "        break\n",
    "\n",
    "n_vertex = int(data[vertex_in + 1][0]) #Number of vertices\n",
    "\n",
    "node_ref = np.zeros((1,3))\n",
    "for i in range(n_vertex):\n",
    "    ii = i + vertex_in + 2\n",
    "    x = float(data[ii][1])\n",
    "    y = float(data[ii][2])\n",
    "    z = float(data[ii][3])\n",
    "    temp = np.array([x,y,z])\n",
    "    node_ref = np.vstack((node_ref,temp))\n",
    "node_ref = node_ref[1:,:] #Vertices\n",
    "\n",
    "## EDGE DATA\n",
    "# loop through each element of the 'data' list\n",
    "for i in range(n_vertex,len(data)):\n",
    "    # check if the current element matches the search value\n",
    "    if data[i] == ['**edge']:\n",
    "        #print(f\"Found '**edge' at index {i}.\")\n",
    "        edge_in = i #Index for edge\n",
    "\n",
    "n_edge = int(data[edge_in + 1][0]) #Number of edges\n",
    "\n",
    "edge_pos = np.zeros((1,2))\n",
    "for i in range(n_edge):\n",
    "    ii = i + edge_in + 2\n",
    "    ini_ = int(data[ii][1])\n",
    "    end_ = int(data[ii][2])\n",
    "    temp = np.array([ini_,end_])\n",
    "    edge_pos = np.vstack((edge_pos,temp))\n",
    "edge_pos = edge_pos[1:,:] #edges\n",
    "\n",
    "## FACE DATA\n",
    "# loop through each element of the 'data' list\n",
    "for i in range(n_edge + edge_in,len(data)):\n",
    "    # check if the current element matches the search value\n",
    "    if data[i] == ['**face']:\n",
    "        #print(f\"Found '**face' at index {i}.\")\n",
    "        face_in = i #Index for face\n",
    "        break\n",
    "\n",
    "n_face = int(data[face_in + 1][0]) #Number of faces\n",
    "\n",
    "off = 2\n",
    "face_vert_f_all = []\n",
    "face_edge_f_all = []\n",
    "for i in range(n_face):\n",
    "    ii = 4*i + face_in + off\n",
    "    face_vert = data[ii] #Vertices that form the face\n",
    "    face_edge = data[ii+1] #Edges that form the face\n",
    "    face_vert_f = [] #Float\n",
    "    face_edge_f = [] #Float\n",
    "    for j in range(len(face_vert)):\n",
    "        face_vert_f.append(float(face_vert[j]))\n",
    "    face_vert_f = np.abs(face_vert_f[2:])\n",
    "    # Array that containts all the vertices for the faces. Useful to find volume without\n",
    "    # having to index edges\n",
    "    face_vert_f_all.append(face_vert_f) \n",
    "    for m in range(len(face_edge)):\n",
    "        face_edge_f.append(float(face_edge[m]))\n",
    "    face_edge_f = np.abs(face_edge_f[1:])\n",
    "    # Array that containts all the edges for the faces\n",
    "    # Note that this has \"the same\" data as face_vert_f_all but \n",
    "    # with edge information instead of vertex information directly.\n",
    "    # This one can be used to create a mesh as it lists the node\n",
    "    # connectivity by edge. They are ordered correctly so they can be indexed.\n",
    "    # For example, face 4 contains edges [4. 25. 26. 15. 27. 28.] which have nodes\n",
    "    # [8. 2. 4. 1. 14. 15.], in that order. These edges can be used to index\n",
    "    # the array edge_pos. For example, edge_pos[3] will give the nodes that make up\n",
    "    # edge 4 (8 2). Then, using this data, one can index node_ref to obtain the coordinates\n",
    "    # of the vertex. THIS PARTICULAR NUMBERS WERE OBTAINED FROM RVE_2\n",
    "    face_edge_f_all.append(face_edge_f) \n",
    "#print(face_edge_f_all[3])\n",
    "#print(face_vert_f_all[3])\n",
    "#print(edge_pos[3])\n",
    "#print(node_ref[7])\n",
    "\n",
    "## POLYHEDRON DATA\n",
    "# loop through each element of the 'data' list\n",
    "for i in range(n_face + face_in,len(data)):\n",
    "    # check if the current element matches the search value\n",
    "    if data[i] == ['**polyhedron']:\n",
    "        #print(f\"Found '**polyhedron' at index {i}.\")\n",
    "        poly_in = i #Index for face\n",
    "        break\n",
    "\n",
    "n_poly = int(data[poly_in + 1][0]) #Number of polyhedrons\n",
    "\n",
    "poly_face_f_all = []\n",
    "for i in range(n_poly):\n",
    "    ii = i + poly_in + 2\n",
    "    poly_face = data[ii] #Faces that form the poly\n",
    "    poly_face_f = [] #Float\n",
    "    for j in range(len(poly_face)):\n",
    "        poly_face_f.append(float(poly_face[j]))\n",
    "    poly_face_f = np.abs(poly_face_f[2:]) \n",
    "    poly_face_f_all.append(poly_face_f) #Array that containts all the faces\n",
    "#print(poly_face_f_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "## PERIODICITY INFO\n",
    "## PERIODICITY SECTION INDEX\n",
    "# loop through each element of the 'data' list\n",
    "for i in range(n_poly + poly_in,len(data)):\n",
    "    # check if the current element matches the search value\n",
    "    if data[i] == ['**periodicity']:\n",
    "        #print(f\"Found '**periodicity' at index {i}.\")\n",
    "        periodicity_in = i #Index for periodicity section\n",
    "        break\n",
    "\n",
    "## VERTEX INFO\n",
    "# loop through each element of the 'data' list\n",
    "for i in range(periodicity_in,len(data)):\n",
    "    # check if the current element matches the search value\n",
    "    if data[i] == ['*vertex']:\n",
    "        #print(f\"Found '*vertex' at index {i}.\")\n",
    "        vertex_per_in = i #Index for periodicity section\n",
    "        break\n",
    "n_vertex_per = int(data[vertex_per_in + 1][0]) #Number of periodic vertices\n",
    "\n",
    "vert_pair = np.zeros((n_vertex_per,5)) # <secondary_ver_id> <primary_ver_id> <per_shift_x> <per_shift_y> <per_shift_z>\n",
    "vert_pair_coord = np.zeros((1,3)) # Coordinates of the periodic vertices. Twice the length of vert_pair always\n",
    "# Ordered as <secondary_ver_coords> in the 2n row, <primary_ver_coords> in the 2n+1 row. n = 0,1,2,...\n",
    "for i in range(n_vertex_per):\n",
    "    ii = i + vertex_per_in + 2\n",
    "    vert_pair_temp = data[ii]  \n",
    "    vert_pair[i,0] = vert_pair_temp[0] #Secondary vertex\n",
    "    vert_pair[i,1] = vert_pair_temp[1] #Primary vertex\n",
    "    vert_pair[i,2] = vert_pair_temp[2] #Periodic shift x\n",
    "    vert_pair[i,3] = vert_pair_temp[3] #Periodic shift y\n",
    "    vert_pair[i,4] = vert_pair_temp[4] #Periodic shift z\n",
    "    #print(vert_pair_temp)\n",
    "    vert_pair_coord = np.vstack((vert_pair_coord,node_ref[int(vert_pair[i,0])-1]))\n",
    "    vert_pair_coord = np.vstack((vert_pair_coord,node_ref[int(vert_pair[i,1])-1]))\n",
    "vert_pair_coord = vert_pair_coord[1:,:]\n",
    "#print(len(vert_pair_coord))\n",
    "\n",
    "## EDGE INFO\n",
    "# loop through each element of the 'data' list\n",
    "for i in range(n_vertex_per + vertex_per_in,len(data)):\n",
    "    # check if the current element matches the search value\n",
    "    if data[i] == ['*edge']:\n",
    "        #print(f\"Found '*edge' at index {i}.\")\n",
    "        edge_per_in = i #Index for periodicity section\n",
    "        break\n",
    "n_edge_per = int(data[edge_per_in + 1][0]) #Number of periodict vertices\n",
    "\n",
    "edge_pair = np.zeros((n_edge_per,2)) # Pair of periodic edges\n",
    "for i in range(n_edge_per):\n",
    "    ii = i + edge_per_in + 2\n",
    "    edge_pair_temp = data[ii] \n",
    "    edge_pair[i,0] = edge_pair_temp[0]\n",
    "    edge_pair[i,1] = edge_pair_temp[1]\n",
    "    #print(edge_pair_temp)\n",
    "#print(edge_pair)   \n",
    "\n",
    "## FACE INFO\n",
    "# loop through each element of the 'data' list\n",
    "for i in range(n_edge_per + edge_per_in,len(data)):\n",
    "    # check if the current element matches the search value\n",
    "    if data[i] == ['*face']:\n",
    "        #print(f\"Found '*face' at index {i}.\")\n",
    "        face_per_in = i #Index for periodicity section\n",
    "        break\n",
    "n_face_per = int(data[face_per_in + 1][0]) #Number of periodic faces\n",
    "\n",
    "face_pair = np.zeros((n_face_per,2)) # Pair of periodic faces\n",
    "for i in range(n_face_per):\n",
    "    ii = i + face_per_in + 2\n",
    "    face_pair_temp = data[ii]\n",
    "    face_pair[i,0] = face_pair_temp[0]\n",
    "    face_pair[i,1] = face_pair_temp[1]\n",
    "    #print(face_pair_temp)\n",
    "#print(face_pair)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_node_to_center(node_coords):\n",
    "    # create array with IDs and coordinates\n",
    "    num_nodes = node_coords.shape[0]\n",
    "    node_ids = np.arange(num_nodes)\n",
    "    geometry = np.column_stack((node_ids, node_coords))\n",
    "\n",
    "    # find center of geometry\n",
    "    center = np.mean(geometry[:, 1:], axis=0)\n",
    "    \n",
    "    # find closest node to center\n",
    "    distances = np.linalg.norm(geometry[:, 1:] - center, axis=1)\n",
    "    closest_node_idx = np.argmin(distances)\n",
    "    closest_node_id = geometry[closest_node_idx, 0]\n",
    "\n",
    "    return int(closest_node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the closest node to the center of the geometry\n",
    "ID_center = find_closest_node_to_center(node_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial guess for deformed RVE is just the original RVE \n",
    "node_def = copy.deepcopy((node_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## trying to create a hashable object \n",
    "class RVE:\n",
    "    def __init__(self,n_poly,poly_face_f_all,face_vert_f_all,face_edge_f_all,edge_pos,node_ref,vert_pair,ID_center,n_edge):\n",
    "        self.n_poly = n_poly\n",
    "        self.poly_face_f_all = poly_face_f_all\n",
    "        self.face_vert_f_all = face_vert_f_all\n",
    "        self.face_edge_f_all = face_edge_f_all\n",
    "        self.edge_pos = edge_pos\n",
    "        self.node_ref = node_ref\n",
    "        self.vert_pair = vert_pair\n",
    "        self.ID_center = ID_center\n",
    "        self.n_edge = n_edge\n",
    "        self.v_poly = 0. #Dummy variable for until we find the actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myRVE = RVE(n_poly,poly_face_f_all,face_vert_f_all,face_edge_f_all,edge_pos,node_ref,vert_pair,ID_center,n_edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hash(myRVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_vert(myRVE): # Find vertices that make up the polyhedra\n",
    "    n_poly = myRVE.n_poly\n",
    "    poly_face_f_all = myRVE.poly_face_f_all\n",
    "    face_vert_f_all = myRVE.face_vert_f_all\n",
    "    verts_poly = []\n",
    "\n",
    "    for i in range(n_poly): #Loop over polyhedrons\n",
    "        #verts = [] # Vertices IDs\n",
    "        verts = np.array([])\n",
    "        current_poly_faces = poly_face_f_all[i]\n",
    "        # let's give a max here and break if possible or do nothing \n",
    "        for j in range(len(current_poly_faces)): #Loop over faces\n",
    "            current_face_vert = face_vert_f_all[int(current_poly_faces[j])-1]\n",
    "            #current_face_edge = face_edge_f_all[int(current_poly_faces[j])-1]\n",
    "            for m in range(len(current_face_vert)):\n",
    "                verts = np.hstack((verts,current_face_vert[m]))\n",
    "                \n",
    "        verts_poly.append(np.unique(verts))     \n",
    "           \n",
    "    return verts_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_v = poly_vert(myRVE)\n",
    "myRVE.v_poly = poly_v # Replace dummy variable for actual value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vol_SA_Dist(node_pos,myRVE):\n",
    "    #node_pos = jnp.array(node_pos)\n",
    "    n_poly = myRVE.n_poly\n",
    "    #poly_face_f_all = myRVE.poly_face_f_all\n",
    "    #face_vert_f_all = myRVE.face_vert_f_all\n",
    "    edge_pos = myRVE.edge_pos\n",
    "    v_poly = myRVE.v_poly\n",
    "    \n",
    "    poly_vol = np.zeros((n_poly,1))\n",
    "    poly_SA = np.zeros((n_poly,1))\n",
    "\n",
    "    kappa = 100. # Strength of convexity constraint \n",
    "    convex = 0. # We want to keep this value equal to zero to be sure all the cells and the geometry is convex\n",
    "           \n",
    "    for i in range(n_poly):\n",
    "        #print(v_poly)\n",
    "        current_v_poly = v_poly[i]\n",
    "        #print(current_v_poly)\n",
    "        v_all = node_pos[current_v_poly.astype(int)-1]\n",
    "        hull = ConvexHull(v_all)\n",
    "        poly_vol[i] = hull.volume\n",
    "        poly_SA[i] = hull.area\n",
    "        if hull.vertices.size != len(v_all):\n",
    "            convex += kappa  \n",
    "            \n",
    "        \n",
    "    v1_coords = node_pos[edge_pos[:,0].astype(int)-1] # Coordinates of the first points\n",
    "    v2_coords = node_pos[edge_pos[:,1].astype(int)-1] # Coordinates of the second points\n",
    "    dist = ((v2_coords[:,0]-v1_coords[:,0])**2 + (v2_coords[:,1]-v1_coords[:,1])**2 + (v2_coords[:,2]-v1_coords[:,2])**2)**0.5\n",
    "    edge_distance = dist.astype(float).reshape(-1,1)\n",
    "\n",
    "    return poly_vol, poly_SA, edge_distance, convex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_Vol_SA_Dist(node_pos,myRVE): #Written by me\n",
    "    #node_pos = jnp.array(node_pos)\n",
    "    n_poly = myRVE.n_poly\n",
    "    #poly_face_f_all = myRVE.poly_face_f_all\n",
    "    #face_vert_f_all = myRVE.face_vert_f_all\n",
    "    edge_pos = myRVE.edge_pos\n",
    "    v_poly = myRVE.v_poly\n",
    "    \n",
    "    poly_vol = np.zeros((n_poly,1))\n",
    "    poly_SA = np.zeros((n_poly,1))\n",
    "\n",
    "    kappa = 100. # Strength of convexity constraint \n",
    "    convex = 0. # We want to keep this value equal to zero to be sure all the cells and the geometry is convex\n",
    "       \n",
    "    ##---------------------------------------##\n",
    "    # initialize the residual vector, three, \n",
    "    # let's do one per metric of interest\n",
    "    n_node = len(node_pos)\n",
    "    # note I am going to flatten it, every node has 3 coords\n",
    "    # so the number of unknowns is 3*n_node \n",
    "    # the residual, just like in FE will have 3*n_node entries \n",
    "    dvoldx = np.zeros((n_node*3)) \n",
    "    dareadx = np.zeros((n_node*3))\n",
    "    dedgedx = np.zeros((n_node*3))\n",
    "    # if you want to get tangent \n",
    "    Kvol = np.zeros((n_node*3,n_node*3)) \n",
    "    Karea = np.zeros((n_node*3,n_node*3)) \n",
    "    Kedge = np.zeros((n_node*3,n_node*3)) \n",
    "    ##---------------------------------------##    \n",
    "    \n",
    "    for i in range(n_poly):\n",
    "        current_v_poly = v_poly[i]\n",
    "        #print(current_v_poly)\n",
    "        v_all = node_pos[current_v_poly.astype(int)-1]\n",
    "        hull = ConvexHull(v_all)\n",
    "        poly_vol[i] = hull.volume\n",
    "        poly_SA[i] = hull.area\n",
    "        \n",
    "    \n",
    "        eps = 1e-6\n",
    "        for ni in range(len(v_all)):\n",
    "            # loop over coordinate\n",
    "            for ci in range(3):\n",
    "                # some variations for central difference\n",
    "                v_all[ni,ci] += eps\n",
    "                # this is the change in volume by moving the node by a little bit\n",
    "                # namely f(x+eps,y) where y represents all other nodal values which stay constant\n",
    "                hull_p_nici = ConvexHull(v_all)\n",
    "                # for central difference \n",
    "                v_all[ni,ci] -= 2*eps\n",
    "                # now evaluating f(x-eps,y)\n",
    "                hull_m_nici = ConvexHull(v_all)\n",
    "                # just undo the variation so v_all goes back to original\n",
    "                v_all[ni,ci] += eps\n",
    "                \n",
    "                # apply finite difference scheme\n",
    "                # use the change in volume to get derivative \n",
    "                dvoldnici = (hull_p_nici.volume-hull_m_nici.volume)/(2*eps)\n",
    "                # this is the change in area\n",
    "                dareadnici = (hull_p_nici.area-hull_m_nici.area)/(2*eps)\n",
    "                # now, the thing is how to assing this to the GLOBAL node \n",
    "                # add to residual since the derivative from multiple polyhedra can add to the\n",
    "                # same nodal entry\n",
    "                # JACQUES: you need to know what is the global index of the node\n",
    "                # see how we are moving node 'ni' of v_all, but what node is that in the\n",
    "                # node_pos array? \n",
    "                global_node_ni = int(current_v_poly[ni])-1\n",
    "                dvoldx[global_node_ni*3+ci] += dvoldnici\n",
    "                dareadx[global_node_ni*3+ci] += dareadnici\n",
    "                \n",
    "                # if you want the tangent then pair of loops more \n",
    "                for nj in range(len(v_all)):\n",
    "                    global_node_nj = int(current_v_poly[nj])-1\n",
    "                    for cj in range(3):\n",
    "                            # variation for second derivative \n",
    "                            # (check multivariate finite differences in\n",
    "                            # https://en.wikipedia.org/wiki/Finite_difference )\n",
    "                            v_all[ni,ci] += eps\n",
    "                            v_all[nj,cj] += eps\n",
    "                            # this is evaluating f(x+eps,y+eps)\n",
    "                            hull_p_nici_p_njcj = ConvexHull(v_all)\n",
    "                            v_all[nj,cj] -= 2*eps\n",
    "                            # this is evaluating f(x+eps,y-eps)\n",
    "                            hull_p_nici_m_njcj = ConvexHull(v_all)\n",
    "                            v_all[ni,ci] -= 2*eps\n",
    "                            # this is evaluating f(x-eps,y-eps)\n",
    "                            hull_m_nici_m_njcj = ConvexHull(v_all)\n",
    "                            v_all[nj,cj] += 2*eps\n",
    "                            # this is evaluating f(x-eps,y+eps)\n",
    "                            hull_m_nici_p_njcj = ConvexHull(v_all)\n",
    "                            # reset v_all\n",
    "                            v_all[ni,ci] += eps\n",
    "                            v_all[nj,cj] -= eps\n",
    "                            \n",
    "                            # second derivative! \n",
    "                            Kvol_nici_njcj = (hull_p_nici_p_njcj.volume - hull_p_nici_m_njcj.volume - hull_m_nici_p_njcj.volume + hull_m_nici_m_njcj.volume)/(4*eps*eps)\n",
    "                            Karea_nici_njcj = (hull_p_nici_p_njcj.area - hull_p_nici_m_njcj.area - hull_m_nici_p_njcj.area + hull_m_nici_m_njcj.area)/(4*eps*eps)\n",
    "                            \n",
    "                            # add to the correct entry \n",
    "                            # note you need again to know, for v_all[nj], what is the corresponding index in node_pos\n",
    "                            # that this corresponds to? \n",
    "                            Kvol[global_node_ni*3+ci,global_node_nj*3+cj] += Kvol_nici_njcj\n",
    "                            Karea[global_node_ni*3+ci,global_node_nj*3+cj] += Karea_nici_njcj\n",
    "        \n",
    "        if hull.vertices.size != len(v_all):\n",
    "            convex += kappa  \n",
    "       \n",
    "    v1_coords = node_pos[edge_pos[:,0].astype(int)-1] # Coordinates of the first points\n",
    "    v2_coords = node_pos[edge_pos[:,1].astype(int)-1] # Coordinates of the second points\n",
    "    dist = ((v2_coords[:,0]-v1_coords[:,0])**2 + (v2_coords[:,1]-v1_coords[:,1])**2 + (v2_coords[:,2]-v1_coords[:,2])**2)**0.5\n",
    "    edge_distance = dist.astype(float).reshape(-1,1)\n",
    "\n",
    "    return poly_vol, poly_SA, edge_distance, convex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Evaluate volume, surface area and edge length for each cell\n",
    "# We need to run this line in order to obtain the values for the reference configuration\n",
    "vol_ref,SA_ref,length_ref,convex_ref = Vol_SA_Dist(node_ref,myRVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vol_def,SA_def,length_def,convex_def = Vol_SA_Dist(node_def,myRVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions to calculate the energy\n",
    "def evalPsi(node_x,myRVE):\n",
    "    \n",
    "    kvol = 0.001\n",
    "    karea = 1.\n",
    "    klength = 1.\n",
    "    \n",
    "    # compute the deformed volumes, areas and lengths \n",
    "    # Evaluate volume, surface area and edge length for each cell\n",
    "    vol_def,SA_def,length_def,convex_def = Vol_SA_Dist(node_x,myRVE)\n",
    "    \n",
    "    # energy is going to be three components \n",
    "    Psi_vol = kvol*np.sum((vol_def - vol_ref)**2)\n",
    "    Psi_area = karea*np.sum((SA_def - SA_ref)**2)/2\n",
    "    Psi_length = klength*np.sum((length_def - length_ref)**2)\n",
    "    \n",
    "    return Psi_vol+Psi_area+Psi_length+convex_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Psis = evalPsi(node_def,myRVE)\n",
    "Psis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 'loss'\n",
    "#@partial(jit, static_argnums=(1,))\n",
    "#@jit\n",
    "def loss_RVE(node_x,myRVE):\n",
    "    #n_poly = poly_info[0]\n",
    "    #poly_face_f_all = poly_info[1]\n",
    "    #face_vert_f_all = poly_info[2]\n",
    "    #face_edge_f_all = poly_info[3]\n",
    "    #edge_pos = poly_info[4]\n",
    "    #node_X = poly_info[5] #node_ref\n",
    "    #BC_pair = poly_info[6] #vert_pair\n",
    "    #ID_center = poly_info[7]\n",
    "    \n",
    "    #myRVE.node_pos = node_x\n",
    "    node_x = node_x.reshape(-1,3)\n",
    "    \n",
    "    # call the energy \n",
    "    Psi_tot = evalPsi(node_x,myRVE)\n",
    "    \n",
    "    # over-write the position of the nodes that we can apply BC to \n",
    "    PBC_penalty = 0\n",
    "    beta = 10000 # penalty to try to enforce the constraint \n",
    "    dPBC = [0.01,0.01,0.01] # the displacements we want to apply \n",
    "    l0 = 0.5 # RVE length\n",
    "    BC_pair = myRVE.vert_pair\n",
    "    n_BC = len(BC_pair)\n",
    "    for i in range(n_BC):\n",
    "        n2 = int(BC_pair[i,0])-1\n",
    "        n1 = int(BC_pair[i,1])-1\n",
    "        #print(node_x[n2,1]-node_x[n1,1])\n",
    "        for j in range(3):\n",
    "            # apply \n",
    "            PBC_penalty += beta*((node_x[n2,j]-node_x[n1,j])-(dPBC[j] + l0)*BC_pair[i,j+2])**2\n",
    "            \n",
    "    # prevent rigid body motions \n",
    "    ID_center = myRVE.ID_center\n",
    "    node_X = myRVE.node_ref\n",
    "    # overwrite completely at least one node for preventing rigid body translation\n",
    "    RBM_penalty = 0\n",
    "    zeta = 10 # penalty to try to enforce the constraint \n",
    "    for i in range(3):\n",
    "        RBM_penalty += zeta*((node_x[ID_center,i])-node_X[ID_center,i])**2\n",
    "    #print(Psi_tot, PBC_penalty, RBM_penalty)\n",
    "    \n",
    "    return Psi_tot + PBC_penalty + RBM_penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss = loss_RVE(node_def,myRVE)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_jp(loss, i, opt_state, myRVE):\n",
    "    node_x = get_params(opt_state)\n",
    "    #print(node_x.shape)\n",
    "    g = grad(loss)(node_x, myRVE)\n",
    "    return opt_update(i, g, opt_state)\n",
    "\n",
    "def train_jp(loss, myRVE, opt_state, key, nIter = 10000):\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    for it in range(nIter):\n",
    "        opt_state = step_jp(loss, it, opt_state, myRVE)         \n",
    "        if (it+1)% 1 == 0:\n",
    "            node_x = get_params(opt_state)\n",
    "            train_loss_value = loss(node_x, myRVE)\n",
    "            train_loss.append(train_loss_value)\n",
    "            to_print = \"it %i, train loss = %e\" % (it+1, train_loss_value)\n",
    "            print(to_print)\n",
    "    return get_params(opt_state), train_loss, val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_init, opt_update, get_params = optimizers.adam(1.e-4) #Original: 1.e-4\n",
    "opt_state = opt_init(node_def)\n",
    "node_x_it1, train_loss, val_loss = train_jp(loss_RVE, myRVE, opt_state, key, nIter = 10) #Original 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### PLOTS ##########\n",
    "# Comment if not needed\n",
    "#plot the RVE\n",
    "#fig = plt.figure()\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.plot(node_ref[:, 0], node_ref[:, 1], node_ref[:, 2], color='peru', linestyle='', marker='.', markersize=3)\n",
    "#plt.show()\n",
    "\n",
    "#plot the RVE boundaries for PBC\n",
    "#fig = plt.figure()\n",
    "#ax = fig.add_subplot(111, projection='3d')\n",
    "#ax.plot(vert_pair_coord[:, 0], vert_pair_coord[:, 1], vert_pair_coord[:, 2], color='peru', linestyle='', marker='.', markersize=3)\n",
    "#plt.show()\n",
    "\n",
    "N = 245\n",
    "n1 = 2*N\n",
    "n2 = n1 + 2\n",
    "\n",
    "ID_center = find_closest_node_to_center(node_ref)\n",
    "\n",
    "# Create a 3D figure and axis\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Plot the point\n",
    "#ax.scatter(vert_pair_coord[n1:n2, 0], vert_pair_coord[n1:n2, 1], vert_pair_coord[n1:n2, 2])\n",
    "ax.scatter(node_ref[ID_center, 0], node_ref[ID_center, 1], node_ref[ID_center, 2])\n",
    "\n",
    "# Set labels for the axes\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n",
    "\n",
    "#print(vert_pair[N,:])\n",
    "#print(vert_pair_coord[n1:n2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the function to minimize\n",
    "def objective(node_x):\n",
    "    return loss_RVE(node_x, myRVE)\n",
    "\n",
    "\n",
    "# run the optimization algorithm\n",
    "res = minimize(objective, node_def.reshape(-1), method='BFGS')\n",
    "\n",
    "# retrieve the optimized node positions\n",
    "node_x_opt = res.x.reshape(-1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
